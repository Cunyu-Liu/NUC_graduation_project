"""è”ç½‘æœç´¢æ¨¡å— - æ”¯æŒå¤šç§æœç´¢å¼•æ“
æä¾›å…è´¹çš„ DuckDuckGo æœç´¢ï¼Œæ— éœ€ API key
"""
import os
import re
import json
import time
import urllib.request
import urllib.parse
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from datetime import datetime


@dataclass
class SearchResult:
    """æœç´¢ç»“æœ"""
    title: str
    url: str
    snippet: str
    source: str = "web"
    timestamp: Optional[str] = None


class WebSearchEngine:
    """ç½‘é¡µæœç´¢å¼•æ“"""
    
    def __init__(self):
        self.last_search_time = 0
        self.min_interval = 1.0  # æœ€å°æœç´¢é—´éš”ï¼ˆç§’ï¼‰
    
    def _rate_limit(self):
        """é€Ÿç‡é™åˆ¶"""
        elapsed = time.time() - self.last_search_time
        if elapsed < self.min_interval:
            time.sleep(self.min_interval - elapsed)
        self.last_search_time = time.time()
    
    def search_duckduckgo(self, query: str, max_results: int = 5) -> List[SearchResult]:
        """
        ä½¿ç”¨ DuckDuckGo æœç´¢ï¼ˆå…è´¹ï¼Œæ— éœ€ API keyï¼‰
        
        Args:
            query: æœç´¢å…³é”®è¯
            max_results: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        try:
            self._rate_limit()
            
            # DuckDuckGo HTML ç‰ˆæœ¬æœç´¢
            encoded_query = urllib.parse.quote_plus(query)
            url = f"https://html.duckduckgo.com/html/?q={encoded_query}"
            
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.0'
            }
            
            req = urllib.request.Request(url, headers=headers)
            with urllib.request.urlopen(req, timeout=15) as response:
                html = response.read().decode('utf-8', errors='ignore')
            
            results = []
            
            # è§£ææœç´¢ç»“æœ
            # DuckDuckGo HTML ç»“æœæ ¼å¼
            result_pattern = r'<a[^>]*class="result__a"[^>]*href="([^"]+)"[^>]*>(.*?)</a>'
            snippet_pattern = r'<a[^>]*class="result__snippet"[^>]*>(.*?)</a>'
            
            titles = re.findall(result_pattern, html, re.DOTALL)
            snippets = re.findall(snippet_pattern, html, re.DOTALL)
            
            for i, (href, title) in enumerate(titles[:max_results]):
                # æ¸…ç† HTML æ ‡ç­¾
                clean_title = re.sub(r'<[^>]+>', '', title).strip()
                clean_snippet = re.sub(r'<[^>]+>', '', snippets[i] if i < len(snippets) else '').strip()
                
                # å¤„ç†é‡å®šå‘ URL
                if href.startswith('/l/'):
                    # æå–å®é™… URL
                    match = re.search(r'uddg=([^&]+)', href)
                    if match:
                        href = urllib.parse.unquote(match.group(1))
                
                if clean_title and href:
                    results.append(SearchResult(
                        title=clean_title,
                        url=href,
                        snippet=clean_snippet,
                        source="DuckDuckGo"
                    ))
            
            return results
            
        except Exception as e:
            print(f"âš ï¸ DuckDuckGo æœç´¢å¤±è´¥: {e}")
            return []
    
    def search_bing(self, query: str, max_results: int = 5) -> List[SearchResult]:
        """
        ä½¿ç”¨ Bing æœç´¢ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰
        éœ€è¦é…ç½® BING_API_KEY ç¯å¢ƒå˜é‡
        """
        api_key = os.getenv('BING_API_KEY')
        if not api_key:
            return []
        
        try:
            self._rate_limit()
            
            url = "https://api.bing.microsoft.com/v7.0/search"
            headers = {"Ocp-Apim-Subscription-Key": api_key}
            params = {"q": query, "count": max_results, "textDecorations": False}
            
            req = urllib.request.Request(
                f"{url}?{urllib.parse.urlencode(params)}",
                headers=headers
            )
            
            with urllib.request.urlopen(req, timeout=10) as response:
                data = json.loads(response.read().decode('utf-8'))
            
            results = []
            for item in data.get('webPages', {}).get('value', []):
                results.append(SearchResult(
                    title=item.get('name', ''),
                    url=item.get('url', ''),
                    snippet=item.get('snippet', ''),
                    source="Bing"
                ))
            
            return results
            
        except Exception as e:
            print(f"âš ï¸ Bing æœç´¢å¤±è´¥: {e}")
            return []
    
    def search(self, query: str, max_results: int = 5) -> List[SearchResult]:
        """
        ç»¼åˆæœç´¢ï¼šå°è¯•å¤šç§æœç´¢å¼•æ“
        
        Args:
            query: æœç´¢å…³é”®è¯
            max_results: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        print(f"ğŸ” æ‰§è¡Œç½‘ç»œæœç´¢: {query[:50]}...")
        
        # ä¼˜å…ˆä½¿ç”¨ DuckDuckGoï¼ˆå…è´¹ï¼‰
        results = self.search_duckduckgo(query, max_results)
        
        # å¦‚æœå¤±è´¥ï¼Œå°è¯• Bing
        if not results:
            results = self.search_bing(query, max_results)
        
        print(f"âœ… æœç´¢å®Œæˆï¼Œæ‰¾åˆ° {len(results)} æ¡ç»“æœ")
        return results
    
    def format_results_for_llm(self, results: List[SearchResult]) -> str:
        """
        å°†æœç´¢ç»“æœæ ¼å¼åŒ–ä¸º LLM å¯ç”¨çš„ä¸Šä¸‹æ–‡
        
        Args:
            results: æœç´¢ç»“æœåˆ—è¡¨
            
        Returns:
            æ ¼å¼åŒ–åçš„æ–‡æœ¬
        """
        if not results:
            return ""
        
        lines = ["ã€ç½‘ç»œæœç´¢ç»“æœã€‘"]
        
        for i, r in enumerate(results, 1):
            lines.append(f"\n{i}. {r.title}")
            lines.append(f"   æ¥æº: {r.source}")
            lines.append(f"   é“¾æ¥: {r.url}")
            lines.append(f"   æ‘˜è¦: {r.snippet}")
        
        return "\n".join(lines)


# å…¨å±€æœç´¢å¼•æ“å®ä¾‹
_search_engine = None

def get_search_engine() -> WebSearchEngine:
    """è·å–æœç´¢å¼•æ“å®ä¾‹ï¼ˆå•ä¾‹ï¼‰"""
    global _search_engine
    if _search_engine is None:
        _search_engine = WebSearchEngine()
    return _search_engine


def web_search(query: str, max_results: int = 5) -> List[SearchResult]:
    """
    ä¾¿æ·çš„æœç´¢å‡½æ•°
    
    Args:
        query: æœç´¢å…³é”®è¯
        max_results: è¿”å›ç»“æœæ•°é‡
        
    Returns:
        æœç´¢ç»“æœåˆ—è¡¨
        
    Example:
        >>> results = web_search("è›‹ç™½è´¨è¯­è¨€æ¨¡å‹æœ€æ–°è¿›å±•", max_results=3)
        >>> for r in results:
        ...     print(f"{r.title}: {r.url}")
    """
    engine = get_search_engine()
    return engine.search(query, max_results)


if __name__ == "__main__":
    # æµ‹è¯•
    results = web_search("Python programming language", max_results=3)
    for r in results:
        print(f"- {r.title}\n  {r.url}\n  {r.snippet[:100]}...\n")
