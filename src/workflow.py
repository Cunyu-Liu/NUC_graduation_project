"""LangGraphå·¥ä½œæµæ¨¡å— - ä½¿ç”¨çŠ¶æ€å›¾ç®¡ç†æ–‡çŒ®åˆ†ææµç¨‹"""
from typing import TypedDict, List, Dict, Any, Optional
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage

from src.config import settings
from src.pdf_parser import PDFParser, ParsedPaper
from src.prompts import get_summary_prompt, get_keypoint_prompt, get_topic_prompt

# å°è¯•å¯¼å…¥LangGraphï¼Œå¦‚æœå¤±è´¥åˆ™æä¾›ç®€åŒ–ç‰ˆæœ¬
try:
    from langgraph.graph import StateGraph, END
    LANGGRAPH_AVAILABLE = True
except ImportError:
    print("è­¦å‘Š: LangGraphæœªå®‰è£…ï¼Œä½¿ç”¨ç®€åŒ–å·¥ä½œæµ")
    LANGGRAPH_AVAILABLE = False


# ============================================================================
# å®šä¹‰çŠ¶æ€ç±»å‹
# ============================================================================

if LANGGRAPH_AVAILABLE:
    class PaperAnalysisState(TypedDict):
        """è®ºæ–‡åˆ†æçš„çŠ¶æ€"""
        # è¾“å…¥
        pdf_path: str
        analysis_tasks: List[str]  # è¦æ‰§è¡Œçš„ä»»åŠ¡åˆ—è¡¨ï¼š['parse', 'summary', 'keypoints', 'topic']

        # ä¸­é—´çŠ¶æ€
        parsed_paper: Optional[ParsedPaper]
        current_step: str

        # è¾“å‡ºç»“æœ
        summary: Optional[str]
        keypoints: Optional[Dict[str, List[str]]]
        topic_analysis: Optional[Dict[str, Any]]

        # é”™è¯¯ä¿¡æ¯
        errors: List[str]
        status: str  # 'pending', 'processing', 'completed', 'failed'
else:
    # å¦‚æœLangGraphä¸å¯ç”¨ï¼Œä½¿ç”¨æ™®é€šå­—å…¸
    PaperAnalysisState = Dict[str, Any]


# ============================================================================
# åˆ›å»ºLLMå®ä¾‹
# ============================================================================

def create_llm(temperature: float = None, model: str = None):
    """åˆ›å»ºLLMå®ä¾‹"""
    return ChatOpenAI(
        model=model or settings.default_model,
        api_key=settings.glm_api_key,
        base_url=settings.glm_base_url,
        temperature=temperature or settings.default_temperature,
        max_tokens=settings.max_tokens,
    )


# ============================================================================
# å®šä¹‰èŠ‚ç‚¹å‡½æ•°
# ============================================================================

async def parse_pdf_node(state: PaperAnalysisState) -> PaperAnalysisState:
    """PDFè§£æèŠ‚ç‚¹"""
    print("ğŸ” æ­¥éª¤1: è§£æPDFæ–‡ä»¶...")

    try:
        parser = PDFParser()
        paper = parser.parse_pdf(state["pdf_path"])

        state["parsed_paper"] = paper
        state["current_step"] = "parse_completed"
        state["status"] = "processing"

        print(f"âœ“ PDFè§£æå®Œæˆ: {paper.filename}")
        print(f"  - æ ‡é¢˜: {paper.metadata.title}")
        print(f"  - é¡µæ•°: {paper.page_count}")

    except Exception as e:
        error_msg = f"PDFè§£æå¤±è´¥: {str(e)}"
        print(f"âœ— {error_msg}")
        state["errors"].append(error_msg)
        state["status"] = "failed"

    return state


async def generate_summary_node(state: PaperAnalysisState) -> PaperAnalysisState:
    """æ‘˜è¦ç”ŸæˆèŠ‚ç‚¹"""
    print("\nğŸ“ æ­¥éª¤2: ç”Ÿæˆæ‘˜è¦...")

    if state.get("parsed_paper") is None:
        error_msg = "ç¼ºå°‘è§£æçš„è®ºæ–‡æ•°æ®"
        print(f"âœ— {error_msg}")
        state["errors"].append(error_msg)
        return state

    try:
        paper = state["parsed_paper"]
        llm = create_llm(temperature=0.3)

        # å‡†å¤‡å†…å®¹
        content = paper.full_text[:6000]  # é™åˆ¶é•¿åº¦
        sections_text = "\n".join([
            f"{name}:\n{content[:500]}"
            for name, content in paper.metadata.sections.items()
        ])

        # æ„å»ºæç¤ºè¯
        prompt = get_summary_prompt(
            title=paper.metadata.title,
            abstract=paper.metadata.abstract,
            sections=sections_text,
            content=content
        )

        # è°ƒç”¨LLM
        response = await llm.ainvoke([HumanMessage(content=prompt)])
        summary = response.content

        state["summary"] = summary
        state["current_step"] = "summary_completed"

        print("âœ“ æ‘˜è¦ç”Ÿæˆå®Œæˆ")
        print(f"\n{summary[:300]}...")

    except Exception as e:
        error_msg = f"æ‘˜è¦ç”Ÿæˆå¤±è´¥: {str(e)}"
        print(f"âœ— {error_msg}")
        state["errors"].append(error_msg)

    return state


async def extract_keypoints_node(state: PaperAnalysisState) -> PaperAnalysisState:
    """è¦ç‚¹æå–èŠ‚ç‚¹"""
    print("\nğŸ¯ æ­¥éª¤3: æå–è¦ç‚¹...")

    if state.get("parsed_paper") is None:
        error_msg = "ç¼ºå°‘è§£æçš„è®ºæ–‡æ•°æ®"
        print(f"âœ— {error_msg}")
        state["errors"].append(error_msg)
        return state

    try:
        paper = state["parsed_paper"]
        llm = create_llm(temperature=0.2)

        # å‡†å¤‡å†…å®¹
        content = paper.full_text[:6000]
        sections_text = "\n".join([
            f"{name}:\n{content[:500]}"
            for name, content in paper.metadata.sections.items()
        ])
        keywords_text = ", ".join(paper.metadata.keywords) if paper.metadata.keywords else "æœªæå–"

        # æ„å»ºæç¤ºè¯
        prompt = get_keypoint_prompt(
            title=paper.metadata.title,
            abstract=paper.metadata.abstract,
            keywords=keywords_text,
            sections=sections_text,
            content=content
        )

        # è°ƒç”¨LLM
        response = await llm.ainvoke([HumanMessage(content=prompt)])
        result = response.content

        # è§£æJSONç»“æœ
        import json
        import re

        # æå–JSON
        json_match = re.search(r'```json\s*(.*?)\s*```', result, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            json_str = result

        keypoints = json.loads(json_str)

        # éªŒè¯ç»“æ„
        required_fields = ["innovations", "methods", "experiments",
                          "conclusions", "contributions", "limitations"]
        for field in required_fields:
            if field not in keypoints:
                keypoints[field] = []

        state["keypoints"] = keypoints
        state["current_step"] = "keypoints_completed"

        print("âœ“ è¦ç‚¹æå–å®Œæˆ")
        for category, items in keypoints.items():
            if items:
                print(f"  - {category}: {len(items)} ä¸ª")

    except Exception as e:
        error_msg = f"è¦ç‚¹æå–å¤±è´¥: {str(e)}"
        print(f"âœ— {error_msg}")
        state["errors"].append(error_msg)
        import traceback
        traceback.print_exc()

    return state


async def analyze_topic_node(state: PaperAnalysisState) -> PaperAnalysisState:
    """ä¸»é¢˜åˆ†æèŠ‚ç‚¹"""
    print("\nğŸ”¬ æ­¥éª¤4: åˆ†æä¸»é¢˜...")

    if state.get("parsed_paper") is None:
        error_msg = "ç¼ºå°‘è§£æçš„è®ºæ–‡æ•°æ®"
        print(f"âœ— {error_msg}")
        state["errors"].append(error_msg)
        return state

    try:
        paper = state["parsed_paper"]
        llm = create_llm(temperature=0.4)

        # å‡†å¤‡å†…å®¹
        content = paper.full_text[:5000]
        keywords_text = ", ".join(paper.metadata.keywords) if paper.metadata.keywords else "æœªæå–"

        # æ„å»ºæç¤ºè¯
        prompt = get_topic_prompt(
            title=paper.metadata.title,
            abstract=paper.metadata.abstract,
            keywords=keywords_text,
            content=content
        )

        # è°ƒç”¨LLM
        response = await llm.ainvoke([HumanMessage(content=prompt)])
        topic_analysis = response.content

        state["topic_analysis"] = {
            "analysis": topic_analysis,
            "keywords": paper.metadata.keywords,
            "title": paper.metadata.title
        }
        state["current_step"] = "topic_completed"

        print("âœ“ ä¸»é¢˜åˆ†æå®Œæˆ")
        print(f"\n{topic_analysis[:300]}...")

    except Exception as e:
        error_msg = f"ä¸»é¢˜åˆ†æå¤±è´¥: {str(e)}"
        print(f"âœ— {error_msg}")
        state["errors"].append(error_msg)

    return state


def should_generate_summary(state: PaperAnalysisState) -> str:
    """åˆ¤æ–­æ˜¯å¦éœ€è¦ç”Ÿæˆæ‘˜è¦"""
    return "summary" in state.get("analysis_tasks", [])


def should_extract_keypoints(state: PaperAnalysisState) -> str:
    """åˆ¤æ–­æ˜¯å¦éœ€è¦æå–è¦ç‚¹"""
    return "keypoints" in state.get("analysis_tasks", [])


def should_analyze_topic(state: PaperAnalysisState) -> str:
    """åˆ¤æ–­æ˜¯å¦éœ€è¦åˆ†æä¸»é¢˜"""
    return "topic" in state.get("analysis_tasks", [])


def finalize_node(state: PaperAnalysisState) -> PaperAnalysisState:
    """å®ŒæˆèŠ‚ç‚¹"""
    state["status"] = "completed"
    print("\nâœ“ æ‰€æœ‰åˆ†æä»»åŠ¡å®Œæˆï¼")
    return state


# ============================================================================
# æ„å»ºå·¥ä½œæµå›¾
# ============================================================================

def create_analysis_workflow():
    """åˆ›å»ºè®ºæ–‡åˆ†æå·¥ä½œæµ"""

    if not LANGGRAPH_AVAILABLE:
        return None

    # åˆ›å»ºçŠ¶æ€å›¾
    workflow = StateGraph(PaperAnalysisState)

    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("parse_pdf", parse_pdf_node)
    workflow.add_node("generate_summary", generate_summary_node)
    workflow.add_node("extract_keypoints", extract_keypoints_node)
    workflow.add_node("analyze_topic", analyze_topic_node)
    workflow.add_node("finalize", finalize_node)

    # è®¾ç½®å…¥å£ç‚¹
    workflow.set_entry_point("parse_pdf")

    # æ·»åŠ æ¡ä»¶è¾¹
    workflow.add_conditional_edges(
        "parse_pdf",
        should_generate_summary,
        {
            True: "generate_summary",
            False: "extract_keypoints"
        }
    )

    workflow.add_conditional_edges(
        "generate_summary",
        should_extract_keypoints,
        {
            True: "extract_keypoints",
            False: "analyze_topic" if should_analyze_topic({"analysis_tasks": []}) else "finalize"
        }
    )

    workflow.add_conditional_edges(
        "extract_keypoints",
        should_analyze_topic,
        {
            True: "analyze_topic",
            False: "finalize"
        }
    )

    workflow.add_conditional_edges(
        "analyze_topic",
        lambda state: "finalize",
        {
            "finalize": "finalize"
        }
    )

    # æ·»åŠ ç»“æŸè¾¹
    workflow.add_edge("finalize", END)

    # ç¼–è¯‘å›¾
    app = workflow.compile()

    return app


# ============================================================================
# ä¸»è¦æ‰§è¡Œå‡½æ•°
# ============================================================================

class PaperAnalysisWorkflow:
    """è®ºæ–‡åˆ†æå·¥ä½œæµåŒ…è£…ç±»"""

    def __init__(self):
        """åˆå§‹åŒ–å·¥ä½œæµ"""
        self.app = create_analysis_workflow()
        self.use_langgraph = LANGGRAPH_AVAILABLE

    async def analyze(
        self,
        pdf_path: str,
        tasks: List[str] = None
    ) -> PaperAnalysisState:
        """
        æ‰§è¡Œå®Œæ•´çš„è®ºæ–‡åˆ†ææµç¨‹

        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            tasks: è¦æ‰§è¡Œçš„ä»»åŠ¡åˆ—è¡¨ï¼Œé»˜è®¤æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡

        Returns:
            PaperAnalysisState: åˆ†æç»“æœçŠ¶æ€
        """
        if tasks is None:
            tasks = ["summary", "keypoints", "topic"]

        # åˆå§‹åŒ–çŠ¶æ€
        initial_state: PaperAnalysisState = {
            "pdf_path": pdf_path,
            "analysis_tasks": tasks,
            "parsed_paper": None,
            "current_step": "initialized",
            "summary": None,
            "keypoints": None,
            "topic_analysis": None,
            "errors": [],
            "status": "pending"
        }

        # æ‰§è¡Œå·¥ä½œæµ
        print("=" * 60)
        print("å¼€å§‹æ‰§è¡Œè®ºæ–‡åˆ†æå·¥ä½œæµ")
        print("=" * 60)

        try:
            if self.app is not None:
                # ä½¿ç”¨LangGraph
                final_state = await self.app.ainvoke(initial_state)
            else:
                # ä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬
                final_state = await self._run_simple_workflow(initial_state)
            return final_state

        except Exception as e:
            print(f"\nâœ— å·¥ä½œæµæ‰§è¡Œå¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            initial_state["status"] = "failed"
            initial_state["errors"].append(str(e))
            return initial_state

    async def _run_simple_workflow(self, state: PaperAnalysisState) -> PaperAnalysisState:
        """ç®€åŒ–çš„å·¥ä½œæµæ‰§è¡Œï¼ˆå½“LangGraphä¸å¯ç”¨æ—¶ï¼‰"""
        # æ­¥éª¤1: è§£æPDF
        state = await parse_pdf_node(state)
        if state["status"] == "failed":
            return state

        # æ­¥éª¤2: ç”Ÿæˆæ‘˜è¦
        if "summary" in state.get("analysis_tasks", []):
            state = await generate_summary_node(state)

        # æ­¥éª¤3: æå–è¦ç‚¹
        if "keypoints" in state.get("analysis_tasks", []):
            state = await extract_keypoints_node(state)

        # æ­¥éª¤4: ä¸»é¢˜åˆ†æ
        if "topic" in state.get("analysis_tasks", []):
            state = await analyze_topic_node(state)

        # å®Œæˆ
        state = finalize_node(state)
        return state

    def analyze_sync(
        self,
        pdf_path: str,
        tasks: List[str] = None
    ) -> PaperAnalysisState:
        """
        åŒæ­¥æ‰§è¡Œè®ºæ–‡åˆ†æï¼ˆå…¼å®¹æ€§æ¥å£ï¼‰

        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            tasks: è¦æ‰§è¡Œçš„ä»»åŠ¡åˆ—è¡¨

        Returns:
            PaperAnalysisState: åˆ†æç»“æœçŠ¶æ€
        """
        import asyncio
        return asyncio.run(self.analyze(pdf_path, tasks))


# ============================================================================
# ä¾¿æ·å‡½æ•°
# ============================================================================

async def analyze_paper_async(
    pdf_path: str,
    tasks: List[str] = None
) -> PaperAnalysisState:
    """
    å¼‚æ­¥åˆ†æè®ºæ–‡

    Args:
        pdf_path: PDFæ–‡ä»¶è·¯å¾„
        tasks: ä»»åŠ¡åˆ—è¡¨

    Returns:
        åˆ†æç»“æœ
    """
    workflow = PaperAnalysisWorkflow()
    return await workflow.analyze(pdf_path, tasks)


def analyze_paper(
    pdf_path: str,
    tasks: List[str] = None
) -> PaperAnalysisState:
    """
    åˆ†æè®ºæ–‡ï¼ˆåŒæ­¥æ¥å£ï¼‰

    Args:
        pdf_path: PDFæ–‡ä»¶è·¯å¾„
        tasks: ä»»åŠ¡åˆ—è¡¨ï¼Œå¦‚ ["summary", "keypoints", "topic"]

    Returns:
        åˆ†æç»“æœ
    """
    workflow = PaperAnalysisWorkflow()
    return workflow.analyze_sync(pdf_path, tasks)
